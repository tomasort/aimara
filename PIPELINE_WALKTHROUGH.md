#!/usr/bin/env python3
"""
AIMARA PIPELINE - COMPLETE WALKTHROUGH
========================================

This document explains step-by-step how the entire pipeline works.

USER COMMAND:
    uv run aimara.py pipeline-process PLAYLIST_URL --max-videos 2 --chunk-length 600

EXECUTION FLOW:
"""

# ==============================================================================
# STAGE 0: COMMAND-LINE INTERFACE (aimara.py)
# ==============================================================================

"""
1. User runs: uv run aimara.py pipeline-process <URL> [OPTIONS]
   
   aimara.py is loaded:
   - Click CLI framework parses arguments
   - Validates playlist URL
   - Sets defaults: model=small, language=es, device=auto, buffer_size=50, chunk_length=600
   
   Example parsed arguments:
   {
       'playlist_url': 'https://www.youtube.com/playlist?list=...',
       'max_videos': 2,
       'model': 'small',
       'language': 'es',
       'device': 'auto',
       'buffer_size': 50,
       'chunk_length': 600
   }

2. CLI displays header:
   ================================================================================
   ðŸš€ Aimara Pipeline - Producer-Consumer Architecture
   ================================================================================
   ðŸ“º Playlist: https://www.youtube.com/playlist?list=...
   ðŸ“Š Max videos: 2
   ðŸ¤– Whisper model: small
   ðŸŒ Language: es
   ðŸ’» Device: auto
   ðŸ“¦ Buffer size: 50
   âœ‚ï¸  Chunk length: 600s (~10 minutes)
   ================================================================================

3. Imports pipeline.py and creates Pipeline instance:
   pipeline = Pipeline(output_dir='.')
   
   Pipeline.__init__() does:
   - Creates directories: audio/, transcripts/, video_transcripts/
   - Sets up paths for later use
"""

# ==============================================================================
# STAGE 1: PIPELINE INITIALIZATION (pipeline.py)
# ==============================================================================

"""
4. pipeline.run() is called with all parameters
   
   Creates three thread-safe queues:
   
   download_queue (maxsize=5)
   â”œâ”€ Holds AudioFile objects
   â””â”€ Producer: DownloadProducer
   â””â”€ Consumer: TranscriptionWorker
   
   transcription_queue (maxsize=50)
   â”œâ”€ Holds TranscriptChunk objects
   â””â”€ Producer: TranscriptionWorker
   â””â”€ Consumer: EntityConsumer

5. THREE THREADS ARE CREATED:

   Thread 1: DownloadProducer
   â”œâ”€ Fetches playlist
   â”œâ”€ Downloads videos one by one
   â”œâ”€ Splits audio into chunks (600s each)
   â””â”€ Puts AudioFile objects into download_queue

   Thread 2: TranscriptionWorker
   â”œâ”€ Loads Whisper model (small, device=auto)
   â”œâ”€ Consumes AudioFile from download_queue
   â”œâ”€ Transcribes each chunk
   â”œâ”€ WRITES transcript to file immediately
   â””â”€ Puts TranscriptChunk into transcription_queue

   Thread 3: EntityConsumer
   â”œâ”€ Loads spaCy model (es_core_news_sm)
   â”œâ”€ Consumes TranscriptChunk from transcription_queue
   â”œâ”€ Extracts entities in batches (buffer_size=50)
   â”œâ”€ Writes JSONL in real-time
   â””â”€ Aggregates per-video files

6. All three threads are started with .start()
   Main thread waits for completion with .join()
"""

# ==============================================================================
# STAGE 2: PARALLEL EXECUTION - DOWNLOAD PRODUCER
# ==============================================================================

"""
Thread: DownloadProducer
Status: RUNNING

Step 1: Fetch Playlist
   - Uses yt_dlp to extract_info() from playlist URL
   - Downloads metadata only (not video/audio yet)
   - Gets list of entries (videos in playlist)
   - Limits to max_videos=2
   
   Example: [Video 1, Video 2]

Step 2: For each video:
   
   VIDEO 1: "Con El Mazo Dando - Programa 548"
   â”œâ”€ video_id: "xyz123"
   â”œâ”€ title: "Con El Mazo Dando ï½œ Diosdado Cabello ï½œ Programa 548"
   â”œâ”€ duration: 14400 (4 hours)
   
   Step 2a: Download audio (yt-dlp FFmpegExtractAudio)
   â”œâ”€ Downloads best audio stream
   â”œâ”€ Converts to MP3 (192 kbps)
   â”œâ”€ Saves to: audio/Video_Title.mp3
   
   Step 2b: Split audio into chunks
   â”œâ”€ Calls split_audio_file()
   â”œâ”€ Uses ffprobe to get duration (14400s)
   â”œâ”€ Splits into: 14400s / 600s = 24 chunks
   â”œâ”€ Creates:
   â”‚  â”œâ”€ audio/Video_Title_chunk_000.mp3 (600s)
   â”‚  â”œâ”€ audio/Video_Title_chunk_001.mp3 (600s)
   â”‚  â”œâ”€ ...
   â”‚  â””â”€ audio/Video_Title_chunk_023.mp3 (600s)
   
   Step 2c: Queue chunks for transcription
   â”œâ”€ For each chunk file created:
   â”‚  â”œâ”€ Create AudioFile object
   â”‚  â”œâ”€ Put into download_queue
   â”‚  â”œâ”€ Log: "Queued: AudioFile(Video_Title chunk 0)"
   â”‚  â””â”€ TranscriptionWorker immediately starts processing
   
   Example first chunk:
   AudioFile(
       path='audio/Video_Title_chunk_000.mp3',
       video_id='xyz123',
       title='Con El Mazo Dando | ...',
       duration=14400
   )

Step 3: Repeat for VIDEO 2
   (Same process for second video)

Step 4: Signal completion
   â”œâ”€ After all videos queued
   â”œâ”€ Put None into download_queue (sentinel value)
   â”œâ”€ Signals TranscriptionWorker: "No more files coming"
   â””â”€ Thread exits

QUEUE STATE DURING DOWNLOAD:
   download_queue: [
       AudioFile(chunk_0), AudioFile(chunk_1), AudioFile(chunk_2),
       AudioFile(chunk_3), AudioFile(chunk_4), ... (maxsize=5)
   ]
"""

# ==============================================================================
# STAGE 3: PARALLEL EXECUTION - TRANSCRIPTION WORKER
# ==============================================================================

"""
Thread: TranscriptionWorker
Status: RUNNING (in parallel with DownloadProducer)

Step 1: Load Whisper model
   â”œâ”€ whisper.load_model('small', device='auto')
   â”œâ”€ Auto-detect device:
   â”‚  â”œâ”€ Check if MPS available (Apple Silicon) -> use MPS
   â”‚  â”œâ”€ Check if CUDA available (NVIDIA) -> use CUDA
   â”‚  â””â”€ Fallback to CPU
   â”œâ”€ Load small model (~500MB)
   â”œâ”€ Log: "Model loaded successfully"

Step 2: Consume AudioFile from queue (with timeout=1s)
   â”œâ”€ audio_file = download_queue.get(timeout=1)
   â”œâ”€ If timeout -> continue (check for sentinel)
   â”œâ”€ If None (sentinel) -> break loop and exit
   â”œâ”€ Otherwise -> process file

   FIRST CHUNK ARRIVES (while DownloadProducer still downloading VIDEO 2):
   
   AudioFile(
       path='audio/Video_Title_chunk_000.mp3',
       video_id='xyz123',
       title='Con El Mazo Dando | ...'
   )

Step 3: Transcribe chunk
   â”œâ”€ Call whisper_model.transcribe(
   â”‚      path='audio/Video_Title_chunk_000.mp3',
   â”‚      language='es',
   â”‚      verbose=False,
   â”‚      fp16=False
   â”‚  )
   â”œâ”€ Whisper processes the 600 seconds of audio
   â”œâ”€ Returns result dict with segments
   
   Example result:
   {
       'text': 'Buenos dÃ­as... (full text)',
       'language': 'es',
       'segments': [
           {'start': 0.0, 'end': 5.2, 'text': 'Buenos dÃ­as'},
           {'start': 5.2, 'end': 12.1, 'text': 'Bienvenidos a...'},
           ...
       ]
   }

Step 4: **IMMEDIATELY WRITE TRANSCRIPT**
   â”œâ”€ Get transcript file for this video:
   â”‚  â””â”€ transcripts/Con_El_Mazo_Dando_transcript_building.txt
   â”œâ”€ Combine all segment texts: 'Buenos dÃ­as\nBienvenidos a\n...'
   â”œâ”€ Append to file (not overwrite!)
   â”œâ”€ f.flush() -> ensures data written to disk
   â”œâ”€ Log: "âœ“ Wrote transcript chunk to: transcripts/Con_El_Mazo_Dando_..."
   
   FILE GROWS IN REAL TIME:
   Initial:
   â”œâ”€ transcripts/Con_El_Mazo_Dando_transcript_building.txt (empty)
   
   After chunk 0:
   â”œâ”€ transcripts/Con_El_Mazo_Dando_transcript_building.txt (600s of text)
   
   After chunk 1:
   â”œâ”€ transcripts/Con_El_Mazo_Dando_transcript_building.txt (1200s of text)

Step 5: Create TranscriptChunk object
   â”œâ”€ Wrap segments in TranscriptSegment objects
   â”œâ”€ Include reference to original AudioFile
   â”œâ”€ Store full concatenated text
   
   TranscriptChunk(
       audio_file=AudioFile(...),
       segments=[
           TranscriptSegment(text='Buenos dÃ­as', start=0.0, end=5.2, ...),
           TranscriptSegment(text='Bienvenidos a...', start=5.2, end=12.1, ...),
           ...
       ],
       full_text='Buenos dÃ­as\nBienvenidos a\n...'
   )

Step 6: Queue for entity extraction
   â”œâ”€ transcription_queue.put(transcript_chunk)
   â”œâ”€ EntityConsumer wakes up and starts processing
   â”œâ”€ Log: "Finished transcribing and queuing: AudioFile(...)"

Step 7: Loop back to Step 2
   â”œâ”€ Consume next AudioFile from download_queue
   â”œâ”€ **While EntityConsumer processes the PREVIOUS chunk!**

EFFICIENCY EXAMPLE:
   Time T=0:    Download Video 1 chunks
   Time T=600:  Transcribe chunk 0 + Write to file
   Time T=605:  Queue chunk 0 for entities
               Download chunk 1 (still downloading)
   Time T=610:  Extract entities from chunk 0
   Time T=1200: Transcribe chunk 1 + Write to file
   Time T=1205: Queue chunk 1 for entities
   Time T=1210: Extract entities from chunk 1
   
   NO WAITING! Everything runs in parallel.
"""

# ==============================================================================
# STAGE 4: PARALLEL EXECUTION - ENTITY CONSUMER
# ==============================================================================

"""
Thread: EntityConsumer
Status: RUNNING (in parallel with Download + Transcription)

Step 1: Load spaCy model
   â”œâ”€ spacy.load('es_core_news_sm')
   â”œâ”€ Spanish NER model
   â”œâ”€ Disable parser and tagger for speed
   â”œâ”€ Log: "Loaded spaCy model: es_core_news_sm"

Step 2: Consume TranscriptChunk from queue
   â”œâ”€ chunk = transcription_queue.get(timeout=1)
   â”œâ”€ FIRST CHUNK ARRIVES (from TranscriptionWorker)
   
   TranscriptChunk(
       audio_file=AudioFile(path='...chunk_000.mp3', video_id='xyz123', ...),
       segments=[...],
       full_text='...'
   )

Step 3: Process all segments in chunk
   â”œâ”€ For each segment in chunk.segments:
   â”‚  â”œâ”€ Add to segment_buffer
   â”‚  â”œâ”€ Increment segment_count
   â”‚  â”œâ”€ Check if buffer full (buffer_size=50)
   â”‚  â””â”€ If full -> call _process_buffer()

   BUFFERING EXAMPLE:
   â”œâ”€ Segment 1 added (buffer has 1)
   â”œâ”€ Segment 2 added (buffer has 2)
   â”œâ”€ ...
   â”œâ”€ Segment 50 added (buffer has 50) -> PROCESS!
   â”‚  â”œâ”€ Extract entities from all 50 segments
   â”‚  â”œâ”€ Write to JSONL
   â”‚  â”œâ”€ Update per-video tracking
   â”‚  â”œâ”€ Clear buffer
   â””â”€ Segment 51 added (buffer has 1)

Step 4: _process_buffer() - Batch entity extraction
   â”œâ”€ Get batch of 50 segments
   â”œâ”€ Extract text from each segment
   â”œâ”€ Batch process with spaCy:
   â”‚  â””â”€ docs = nlp.pipe(batch_texts, batch_size=25, disable=[...])
   â”‚     (Faster than processing one-by-one)
   
   â”œâ”€ For each (doc, segment) pair:
   â”‚  â””â”€ Extract named entities:
   â”‚     â”œâ”€ PERSON: "Diosdado Cabello"
   â”‚     â”œâ”€ ORG: "PSUV"
   â”‚     â”œâ”€ GPE: "Venezuela"
   â”‚     â””â”€ MISC: (other)
   
   â”‚  â””â”€ Extract custom patterns:
   â”‚     â”œâ”€ POLITICAL_TITLES: "presidente Maduro"
   â”‚     â”œâ”€ ORGANIZATIONS: "FANB", "GNB", "SEBIN"
   â”‚     â”œâ”€ PROGRAMS: "programa 548"
   â”‚     â””â”€ COUNTRIES: geographic names
   
   â”œâ”€ For each entity found:
   â”‚  â”œâ”€ Increment entity count
   â”‚  â”œâ”€ Add to global entity_database
   â”‚  â”œâ”€ Add to video-specific entity_database
   â”‚  â””â”€ Call _write_entity() to JSONL

Step 5: _write_entity() - Real-time JSONL output
   â”œâ”€ Open entities_YYYYMMDD_HHMMSS.jsonl in append mode
   â”œâ”€ Write entity as JSON line:
   â”‚  {
   â”‚      "entity": "Diosdado Cabello",
   â”‚      "type": "PERSON",
   â”‚      "video_info": {"title": "...", "video_id": "xyz123", ...},
   â”‚      "timestamp_start": 120.5,
   â”‚      "timestamp_end": 125.3,
   â”‚      "context": "Diosdado Cabello hablÃ³...",
   â”‚      "extraction_time": "2025-10-28T15:30:45.123456"
   â”‚  }
   â”œâ”€ f.flush() -> disk write
   â”œâ”€ Result: File grows in real-time!

Step 6: Track per-video
   â”œâ”€ Store entities in: video_entities[video_id][entity_name]
   â”œâ”€ Store segments in: video_segments[video_id]
   â”œâ”€ Used later for per-video files

Step 7: Loop back
   â”œâ”€ Check if buffer >= 50 -> process if full
   â”œâ”€ Consume next chunk
   â”œâ”€ Continue until sentinel (None) received

REAL-TIME OBSERVATION:
   Terminal 1 (running pipeline):
   INFO [EntityConsumer] Processing buffer with 50 segments
   INFO [EntityConsumer] Found 234 entities in batch
   
   Terminal 2 (monitoring files):
   $ tail -f transcripts/entities_*.jsonl
   {"entity": "Diosdado", "type": "PERSON", ...}
   {"entity": "PSUV", "type": "ORG", ...}
   {"entity": "Venezuela", "type": "GPE", ...}
   (new entities appearing in real-time!)
"""

# ==============================================================================
# STAGE 5: FINALIZATION
# ==============================================================================

"""
When all three threads complete:

DownloadProducer: FINISHED
â”œâ”€ All videos queued
â””â”€ Sent sentinel (None) to download_queue

TranscriptionWorker: FINISHED
â”œâ”€ Received sentinel
â”œâ”€ Sent sentinel to transcription_queue
â””â”€ Exited

EntityConsumer: FINALIZE
â”œâ”€ Received sentinel
â”œâ”€ Process remaining buffer segments
â”œâ”€ Call _finalize()

_finalize() does:

1. Process remaining buffer
   â”œâ”€ If buffer has < 50 segments -> still process them!
   â”œâ”€ Don't lose data!

2. Save per-video transcript files
   â”œâ”€ For each video_id in video_segments:
   â”‚  â”œâ”€ Read intermediate file: Con_El_Mazo_Dando_transcript_building.txt
   â”‚  â”œâ”€ Create final files:
   â”‚  â”‚  â”œâ”€ video_transcripts/Con_El_Mazo_Dando_transcript.txt (full text)
   â”‚  â”‚  â”œâ”€ video_transcripts/Con_El_Mazo_Dando_transcript.json (segmented)
   â”‚  â”‚  â””â”€ video_transcripts/Con_El_Mazo_Dando_entities.json (entities)
   â”‚  â””â”€ Delete intermediate _building.txt file

3. Save global summary
   â”œâ”€ transcripts/entities_summary_YYYYMMDD_HHMMSS.json
   â”œâ”€ Contains:
   â”‚  â”œâ”€ total_segments_processed: 5000
   â”‚  â”œâ”€ total_entities_found: 2340
   â”‚  â”œâ”€ entity_counts by category
   â”‚  â””â”€ timestamp

4. Return results to CLI
   â””â”€ {
         'entities_file': '.../entities_YYYYMMDD_HHMMSS.jsonl',
         'summary_file': '.../entities_summary_YYYYMMDD_HHMMSS.json',
         'video_transcripts_dir': '.../video_transcripts/',
         'total_entities': 2340,
         'total_segments': 5000,
         'total_videos': 2
      }
"""

# ==============================================================================
# STAGE 6: CLI OUTPUT
# ==============================================================================

"""
CLI displays final results:

âœ… Pipeline completed successfully!

ðŸ“Š Results:
   ðŸŽ¬ Total segments processed: 5000
   ðŸŽ¥ Total videos processed: 2
   ðŸ” Total entities extracted: 2340

ðŸ“ Output files:
   ðŸ“„ Global entities (JSONL): ./transcripts/entities_20251028_153045.jsonl
   ðŸ“Š Global summary: ./transcripts/entities_summary_20251028_153045.json
   ðŸ“‚ Per-video files: ./video_transcripts/
      â”œâ”€ VIDEO_transcript.txt (full transcript)
      â”œâ”€ VIDEO_transcript.json (segmented transcript)
      â””â”€ VIDEO_entities.json (entities for that video)
"""

# ==============================================================================
# DIRECTORY STRUCTURE AFTER COMPLETION
# ==============================================================================

"""
./
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ Video_Title_1.mp3
â”‚   â”œâ”€â”€ Video_Title_1_chunk_000.mp3
â”‚   â”œâ”€â”€ Video_Title_1_chunk_001.mp3
â”‚   â”œâ”€â”€ ...
â”‚   â”œâ”€â”€ Video_Title_2.mp3
â”‚   â”œâ”€â”€ Video_Title_2_chunk_000.mp3
â”‚   â””â”€â”€ ...
â”œâ”€â”€ transcripts/
â”‚   â”œâ”€â”€ entities_20251028_153045.jsonl
â”‚   â”‚   â”œâ”€ Line 1: {"entity": "Diosdado", ...}
â”‚   â”‚   â”œâ”€ Line 2: {"entity": "PSUV", ...}
â”‚   â”‚   â””â”€ ... (2340 lines)
â”‚   â””â”€â”€ entities_summary_20251028_153045.json
â”‚       â””â”€ {"total_entities": 2340, "entity_counts": {...}, ...}
â””â”€â”€ video_transcripts/
    â”œâ”€â”€ Video_Title_1_transcript.txt
    â”‚   â””â”€ (full transcript of video 1)
    â”œâ”€â”€ Video_Title_1_transcript.json
    â”‚   â””â”€ {"segments": [...], "text": "...", ...}
    â”œâ”€â”€ Video_Title_1_entities.json
    â”‚   â””â”€ {"Diosdado": {...}, "PSUV": {...}, ...}
    â”œâ”€â”€ Video_Title_2_transcript.txt
    â”œâ”€â”€ Video_Title_2_transcript.json
    â””â”€â”€ Video_Title_2_entities.json
"""

# ==============================================================================
# KEY PARALLELISM MOMENTS
# ==============================================================================

"""
Why this is SO much faster than sequential processing:

SEQUENTIAL (OLD):
   Download Video 1 (600s) -> Transcribe Video 1 (3000s) -> Extract entities (500s)
   Download Video 2 (600s) -> Transcribe Video 2 (3000s) -> Extract entities (500s)
   TOTAL: ~9000 seconds (2.5 hours)

PARALLEL (NEW):
   Time 0-600s:    Download Video 1 + Video 2 chunks
   Time 600-1200s: Transcribe chunk 1 + Download chunk 3 + Extract entities from chunk 0
   Time 1200-1800: Transcribe chunk 2 + Download chunk 4 + Extract entities from chunk 1
   ...
   TOTAL: ~2000-2500 seconds (30-40 minutes)
   
   SPEEDUP: 4-5x faster!
"""

# ==============================================================================
# ERROR HANDLING
# ==============================================================================

"""
What happens if something fails:

1. MPS NaN Error (GPU problem):
   â”œâ”€ Caught in TranscriptionWorker
   â”œâ”€ Falls back to CPU
   â”œâ”€ Continues processing (slower but works)

2. Network Error (download fails):
   â”œâ”€ Caught in DownloadProducer
   â”œâ”€ Logged with error message
   â”œâ”€ Continues with next video

3. File I/O Error:
   â”œâ”€ Caught in EntityConsumer._write_entity()
   â”œâ”€ Logged but doesn't stop processing
   â”œâ”€ Critical files (final JSON) still get saved

4. spaCy model missing:
   â”œâ”€ Caught in EntityConsumer.__init__()
   â”œâ”€ Logs warning
   â”œâ”€ Only spaCy entities skipped, patterns still work

5. Sentinel handling:
   â”œâ”€ None in queue signals end
   â”œâ”€ Each thread checks for None
   â”œâ”€ Gracefully exits
"""

print("=" * 80)
print("WALKTHROUGH COMPLETE")
print("=" * 80)
print("""
The pipeline is a three-stage producer-consumer system:

1. DownloadProducer (Thread 1)
   â”œâ”€ Downloads videos from playlist
   â”œâ”€ Splits into chunks for faster processing
   â””â”€ Queues AudioFile objects

2. TranscriptionWorker (Thread 2)
   â”œâ”€ Consumes AudioFile
   â”œâ”€ Transcribes with Whisper
   â”œâ”€ **WRITES TRANSCRIPT IMMEDIATELY**
   â””â”€ Queues TranscriptChunk

3. EntityConsumer (Thread 3)
   â”œâ”€ Consumes TranscriptChunk
   â”œâ”€ Extracts entities in batches (buffer_size=50)
   â”œâ”€ **WRITES ENTITIES TO JSONL IN REAL-TIME**
   â””â”€ Aggregates per-video files

MAXIMUM PARALLELISM:
- While downloading video 3, transcribing video 2, extracting entities from video 1
- All three stages running simultaneously
- Thread-safe queues handle communication
- Real-time file output allows monitoring

RUN COMMAND:
    uv run aimara.py pipeline-process PLAYLIST_URL --max-videos 2 --chunk-length 600
""")
