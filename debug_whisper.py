#!/usr/bin/env python3
"""
Script to pre-download Whisper models and test transcription worker.
This helps debug the hanging issue by isolating the model download step.
"""

import whisper
import torch
import sys
import os
from pathlib import Path

def test_device_detection():
    """Test device detection and availability."""
    print("ğŸ” Testing device detection...")
    
    # Check CUDA
    if torch.cuda.is_available():
        device = "cuda"
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)
        print(f"âœ… CUDA available: {gpu_name} ({gpu_memory:.1f}GB)")
    # Check MPS (Apple Silicon)
    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        device = "mps"
        print("âœ… MPS (Apple Silicon GPU) available")
    else:
        device = "cpu"
        print("âš ï¸  Using CPU (no GPU acceleration)")
    
    print(f"ğŸ¯ Selected device: {device}")
    return device

def download_whisper_models():
    """Pre-download Whisper models to avoid runtime issues."""
    models = ["tiny", "base", "small", "medium"]
    
    print("\nğŸ“¥ Pre-downloading Whisper models...")
    print("This may take a few minutes but will prevent runtime hangs...")
    
    for model_name in models:
        try:
            print(f"\nâ¬‡ï¸  Downloading {model_name} model...")
            model = whisper.load_model(model_name)
            print(f"âœ… {model_name} model downloaded successfully")
            
            # Test the model briefly
            print(f"ğŸ§ª Testing {model_name} model...")
            # Create a short silent audio for testing
            import numpy as np
            test_audio = np.zeros(16000, dtype=np.float32)  # 1 second of silence
            result = model.transcribe(test_audio, language="es")
            print(f"âœ… {model_name} model test successful")
            
            del model  # Free memory
            
        except Exception as e:
            print(f"âŒ Failed to download/test {model_name} model: {e}")
            if "name resolution" in str(e).lower():
                print("ğŸŒ Network/DNS issue detected!")
                print("Solutions:")
                print("   1. Check internet connection")
                print("   2. Try different DNS (8.8.8.8)")
                print("   3. Use VPN if network blocks downloads")
                return False
    
    print("\nâœ… All models downloaded and tested successfully!")
    return True

def test_transcription_worker():
    """Test the transcription worker in isolation."""
    print("\nğŸ§ª Testing transcription worker...")
    
    device = test_device_detection()
    
    try:
        print(f"\nğŸ“¤ Loading tiny model on {device}...")
        model = whisper.load_model("tiny", device=device)
        print("âœ… Model loaded successfully")
        
        # Create test audio
        import numpy as np
        test_audio = np.zeros(16000 * 5, dtype=np.float32)  # 5 seconds of silence
        
        print("ğŸ¤ Transcribing test audio...")
        result = model.transcribe(test_audio, language="es")
        print(f"âœ… Transcription successful: '{result['text'].strip()}'")
        
        return True
        
    except Exception as e:
        print(f"âŒ Transcription worker test failed: {e}")
        
        if "name resolution" in str(e).lower():
            print("\nğŸŒ DNS/Network issue:")
            print("   - Server can't download Whisper models")
            print("   - Check internet connection")
            print("   - Try: export DNS=8.8.8.8")
            
        elif "out of memory" in str(e).lower():
            print("\nğŸ’¾ GPU Memory issue:")
            print("   - Try smaller model (tiny instead of medium)")
            print("   - Try CPU: --device cpu")
            
        elif "cuda" in str(e).lower():
            print("\nğŸ® CUDA issue:")
            print("   - Check CUDA installation")
            print("   - Try CPU: --device cpu")
            
        return False

def check_network_connectivity():
    """Check if we can reach model download URLs."""
    print("\nğŸŒ Testing network connectivity...")
    
    import urllib.request
    import socket
    
    urls_to_test = [
        "https://openaipublic.azureedge.net",  # Whisper models
        "https://github.com",                  # General connectivity
        "https://google.com",                  # DNS test
    ]
    
    for url in urls_to_test:
        try:
            print(f"   Testing {url}...")
            response = urllib.request.urlopen(url, timeout=10)
            print(f"   âœ… {url} - OK ({response.code})")
        except Exception as e:
            print(f"   âŒ {url} - FAILED: {e}")
            if "name resolution" in str(e).lower():
                print("      ğŸ”§ DNS resolution failed - check DNS settings")
            return False
    
    print("âœ… Network connectivity looks good")
    return True

def main():
    print("=" * 80)
    print("ğŸ”§ Whisper Model Download & Transcription Test")
    print("=" * 80)
    
    # Test network first
    if not check_network_connectivity():
        print("\nâŒ Network issues detected. Fix network connectivity first.")
        sys.exit(1)
    
    # Test device detection
    device = test_device_detection()
    
    # Pre-download models
    if not download_whisper_models():
        print("\nâŒ Model download failed. Check error messages above.")
        sys.exit(1)
    
    # Test transcription worker
    if not test_transcription_worker():
        print("\nâŒ Transcription worker test failed.")
        sys.exit(1)
    
    print("\n" + "=" * 80)
    print("âœ… ALL TESTS PASSED!")
    print("ğŸš€ Your setup should work with the main pipeline now.")
    print("=" * 80)

if __name__ == "__main__":
    main()